## 十亿、百亿级数据扩展性与性能瓶颈

高斯数据库Datavec模块2025.03版本在处理亿级数据时的挑战：

### 构建瓶颈:

内存限制: maintenance_work_mem是硬上限。对于亿级数据，内存构建阶段很快结束，绝大部分时间将消耗在缓慢的、产生大量WAL日志的磁盘插入上。

I/O放大: 每次插入都需要读写多个页面（更新邻居、元数据页），并产生WAL。

### 搜索瓶颈:

随机I/O: 最核心的瓶颈。亿级图数据远超内存容量，即使2025.03版本引入mmap也无法解决物理磁盘的随机读延迟。每次跳跃到一个新邻居都可能是一次磁盘寻道。这导致P99延迟非常高。

CPU与I/O倒挂: 在I/O密集型场景下，CPU大部分时间在等待数据从磁盘加载，SIMD等计算优化带来的收益被掩盖。

### 维护瓶颈:

VACUUM频繁: 大量更新/删除后的VACUUM，其RepairGraph阶段会触发全图范围内的读写，对系统造成巨大冲击。

## 基于RabitQ理念重构 (HNSW\_rabitq)

**RabitQ重构**的核心思想是通过**精心设计的量化方案和数据布局**，将随机访存的距离计算转变为**可批处理的、顺序访存的、仅计算（compute-only）的**过程，从而根本上解决I/O瓶颈并充分发挥SIMD的威力。

**下面将DATAVEC的核心模块，用**RabitQ**的理念进行改造。**

### 改造目标

* **量化方案**: 引入RabitQ，取代原有的PQ。RabitQ生成码字和三个因子**f\_add, f\_rescale, f\_error**，用于无重排的距离估计。
* **数据布局**: 改造索引文件的物理布局，将量化后的码字和因子**连续存储**，以支持顺序读和FastScan。
* **计算加速**: 使用ARM NEON指令集实现FastScan，批量计算距离。
* **搜索逻辑**: 改造搜索流程，直接使用估计距离进行图导航，消除重排阶段。
